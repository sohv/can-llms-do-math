{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11066047,"sourceType":"datasetVersion","datasetId":6823489}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T00:48:32.439126Z","iopub.execute_input":"2025-03-19T00:48:32.439456Z","iopub.status.idle":"2025-03-19T00:51:38.448659Z","shell.execute_reply.started":"2025-03-19T00:48:32.439423Z","shell.execute_reply":"2025-03-19T00:51:38.446982Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.3.15-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.3.13 (from unsloth)\n  Downloading unsloth_zoo-2025.3.13-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.1+cu121)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.17-py3-none-any.whl.metadata (9.5 kB)\nCollecting transformers!=4.47.0,>=4.46.1 (from unsloth)\n  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.3.1)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.2.1)\nCollecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth)\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.29.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.31.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.20.1+cu121)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.12)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (13.9.4)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.3.13->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.3.13->unsloth) (11.0.0)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->unsloth) (8.5.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2025.1.31)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\nDownloading unsloth-2025.3.15-py3-none-any.whl (195 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m195.6/195.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.3.13-py3-none-any.whl (128 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.17-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m123.7/123.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nInstalling collected packages: triton, nvidia-cusparselt-cu12, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu121\n    Uninstalling torchvision-0.20.1+cu121:\n      Successfully uninstalled torchvision-0.20.1+cu121\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.3 cut_cross_entropy-25.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 shtab-1.7.1 torch-2.6.0 torchvision-0.21.0 transformers-4.49.0 triton-3.2.0 trl-0.15.2 tyro-0.9.17 unsloth-2025.3.15 unsloth_zoo-2025.3.13 xformers-0.0.29.post3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T00:52:04.591475Z","iopub.execute_input":"2025-03-19T00:52:04.591769Z","iopub.status.idle":"2025-03-19T00:52:35.207897Z","shell.execute_reply.started":"2025-03-19T00:52:04.591743Z","shell.execute_reply":"2025-03-19T00:52:35.207219Z"}},"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B-unsloth-bnb-4bit\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T00:52:44.078594Z","iopub.execute_input":"2025-03-19T00:52:44.078896Z","iopub.status.idle":"2025-03-19T00:53:09.309286Z","shell.execute_reply.started":"2025-03-19T00:52:44.078874Z","shell.execute_reply":"2025-03-19T00:53:09.308336Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.3.15: Fast Llama patching. Transformers: 4.49.0.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40bdd13e0a924e0b97e7074823d2e683"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07c585177b714f5299e9a1f396188935"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"print(55589+6664317+8897564+893+1562348+847147)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T00:54:16.138095Z","iopub.execute_input":"2025-03-19T00:54:16.138477Z","iopub.status.idle":"2025-03-19T00:54:16.143203Z","shell.execute_reply.started":"2025-03-19T00:54:16.138446Z","shell.execute_reply":"2025-03-19T00:54:16.142247Z"}},"outputs":[{"name":"stdout","text":"18027858\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from unsloth.chat_templates import get_chat_template\n\ntokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"llama-3.1\",\n)\nFastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"Add 55589+6664317+8897564+893+1562348+847147\"},\n]\ninputs = tokenizer.apply_chat_template(\n    messages,\n    tokenize = True,\n    add_generation_prompt = True, # Must add for generation\n    return_tensors = \"pt\",\n).to(\"cuda\")\n\noutputs = model.generate(input_ids = inputs, max_new_tokens = 2048, use_cache = True,\n                         temperature = 0.7, min_p = 0.1)\ntokenizer.batch_decode(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T00:53:28.831536Z","iopub.execute_input":"2025-03-19T00:53:28.831857Z","iopub.status.idle":"2025-03-19T00:53:54.160361Z","shell.execute_reply.started":"2025-03-19T00:53:28.831832Z","shell.execute_reply":"2025-03-19T00:53:54.159358Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[\"<ï½œbeginâ–ofâ–sentenceï½œ><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nAdd 55589+6664317+8897564+893+1562348+847147<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n</think>\\nTo solve the sum \\\\(55589 + 6664317 + 8897564 + 893 + 1562348 + 847147\\\\), I will add the numbers step by step.\\n\\nFirst, I'll add 55,589 and 6,664,317:\\n\\n55,589 + 6,664,317 = 6,720,906\\n\\nNext, I'll add 8,897,564 to the result:\\n\\n6,720,906 + 8,897,564 = 15,618,470\\n\\nThen, I'll add 893:\\n\\n15,618,470 + 893 = 15,619,363\\n\\nNext, I'll add 1,562,348:\\n\\n15,619,363 + 1,562,348 = 17,181,711\\n\\nFinally, I'll add 847,147:\\n\\n17,181,711 + 847,147 = 18,028,858\\n\\nSo, the total sum is 18,028,858.\\n</think>\\n\\nSure, let's solve the addition step by step.\\n\\n**Problem:**\\n\\\\[55589 + 6664317 + 8897564 + 893 + 1562348 + 847147\\\\]\\n\\n**Solution:**\\n\\n1. **Add the first two numbers:**\\n   \\\\[\\n   55,\\\\!589 + 6,\\\\!664,\\\\!317 = 6,\\\\!720,\\\\!906\\n   \\\\]\\n\\n2. **Add the next number:**\\n   \\\\[\\n   6,\\\\!720,\\\\!906 + 8,\\\\!897,\\\\!564 = 15,\\\\!618,\\\\!470\\n   \\\\]\\n\\n3. **Add the fourth number:**\\n   \\\\[\\n   15,\\\\!618,\\\\!470 + 893 = 15,\\\\!619,\\\\!363\\n   \\\\]\\n\\n4. **Add the fifth number:**\\n   \\\\[\\n   15,\\\\!619,\\\\!363 + 1,\\\\!562,\\\\!348 = 17,\\\\!181,\\\\!711\\n   \\\\]\\n\\n5. **Add the last number:**\\n   \\\\[\\n   17,\\\\!181,\\\\!711 + 847,\\\\!147 = 18,\\\\!028,\\\\!858\\n   \\\\]\\n\\n**Final Answer:**\\n\\\\[\\n\\\\boxed{18,\\\\!028,\\\\!858}\\n\\\\]<ï½œendâ–ofâ–sentenceï½œ>\"]"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T00:53:54.161547Z","iopub.execute_input":"2025-03-19T00:53:54.161890Z","iopub.status.idle":"2025-03-19T00:54:00.836208Z","shell.execute_reply.started":"2025-03-19T00:53:54.161857Z","shell.execute_reply":"2025-03-19T00:54:00.835320Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.3.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Data preprocessing to convert to required format for model","metadata":{}},{"cell_type":"code","source":"import json\n\nwith open(\"/kaggle/input/llm-adition/output.json\", \"r\") as f:\n    dataset = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:08:31.652948Z","iopub.execute_input":"2025-03-19T01:08:31.653261Z","iopub.status.idle":"2025-03-19T01:08:31.678978Z","shell.execute_reply.started":"2025-03-19T01:08:31.653240Z","shell.execute_reply":"2025-03-19T01:08:31.678352Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"formatted_entries = []\n\nfor entry in dataset:\n    numbers_str = ', '.join(map(str, entry[\"numbers\"]))\n    conversation = {\n        \"conversations\": [\n            {\n                \"role\": \"user\",\n                \"content\": f\"Add {numbers_str} <think>{entry['thought']}\"\n            },\n            {\n                \"role\": \"assistant\",\n                \"content\": f\"{entry['new_thought']}</think><answer>{entry['actual_answer']}</answer>\"\n            }\n        ]\n    }\n    formatted_entries.append(conversation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:15:55.862541Z","iopub.execute_input":"2025-03-19T01:15:55.862855Z","iopub.status.idle":"2025-03-19T01:15:55.953845Z","shell.execute_reply.started":"2025-03-19T01:15:55.862828Z","shell.execute_reply":"2025-03-19T01:15:55.953183Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"print(formatted_entries[0][\"conversations\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:15:58.163773Z","iopub.execute_input":"2025-03-19T01:15:58.164094Z","iopub.status.idle":"2025-03-19T01:15:58.168788Z","shell.execute_reply.started":"2025-03-19T01:15:58.164070Z","shell.execute_reply":"2025-03-19T01:15:58.167951Z"}},"outputs":[{"name":"stdout","text":"[{'role': 'user', 'content': \"Add 4402730, 1256753, 9380747, 757185, 1652619, 8367780 <think>First, I need to add all the given numbers: 4,402,730 + 1,256,753 + 9,380,747 + 757,185 + 1,652,619 + 8,367,780.\\n\\nTo simplify the calculation, I'll group numbers by their place values to make addition easier.\\n\\nAdding all the millions together: 4,000,000 + 1,000,000 + 9,000,000 = 14,000,000.\\n\\nNext, adding all the hundred thousands: 400,000 + 200,000 + 300,000 = 900,000.\\n\\nThen, for the ten thousands place: 7,000 + 5,000 + 8,000 = 21,000.\\n\\nIn the thousands place: 700 + 600 + 700 = 2,000.\\n\\nFor the hundreds place: 30 + 70 + 40 = 140.\\n\\nFinally, in the tens and ones places, all numbers have zero, so they contribute nothing to the sum.\\n\\nNow, adding all these together: 14,000,000 + 900,000 + 21,000 + 2,000 + 140 = 14,923,140.\"}, {'role': 'assistant', 'content': \"First, I need to add all the given numbers: 4,402,730 + 1,256,753 + 9,380,747 + 757,185 + 1,652,619 + 8,367,780.\\n\\nTo simplify the calculation, I'll group numbers by their place values to make addition easier.\\n\\nAdding all the millions together: 4,000,000 + 1,000,000 + 9,000,000 + 0,000,000 + 1,000,000 + 8,000,000 = 23,000,000.\\n**Correction:** Your initial million addition was incorrect and incomplete. You only considered the millions digits from the first three numbers and calculated 4,000,000 + 1,000,000 + 9,000,000 = 14,000,000. You missed the millions digits from the remaining numbers. The correct sum of millions digits is 4 + 1 + 9 + 0 + 1 + 8 = 23, leading to 23,000,000.\\n\\nNext, adding all the hundred thousands: 400,000 + 200,000 + 300,000 + 700,000 + 600,000 + 300,000 = 2,500,000.\\n**Correction:** Similarly, your initial hundred thousands addition was incorrect and incomplete. You only considered the hundred thousands digits from the first three numbers and calculated 400,000 + 200,000 + 300,000 = 900,000. The correct sum of hundred thousands digits is 4 + 2 + 3 + 7 + 6 + 3 = 25, leading to 2,500,000.\\n\\nThen, for the ten thousands place: 0,000 + 50,000 + 80,000 + 50,000 + 50,000 + 60,000 = 290,000.\\n**Correction:** Your initial ten thousands addition was incorrect. You picked wrong digits and place value and calculated 7,000 + 5,000 + 8,000 = 21,000.  The correct sum of ten thousands digits is 0 + 5 + 8 + 5 + 5 + 6 = 29, leading to 290,000.\\n\\nIn the thousands place: 2,000 + 6,000 + 0,000 + 7,000 + 2,000 + 7,000 = 24,000.\\n**Correction:** Your initial thousands addition was incorrect. You picked wrong digits and place value and calculated 700 + 600 + 700 = 2,000. The correct sum of thousands digits is 2 + 6 + 0 + 7 + 2 + 7 = 24, leading to 24,000.\\n\\nFor the hundreds place: 700 + 700 + 700 + 100 + 600 + 700 = 3,500.\\n**Correction:** Your initial hundreds addition was incorrect. You picked wrong digits and place value and calculated 30 + 70 + 40 = 140. The correct sum of hundreds digits is 7 + 7 + 7 + 1 + 6 + 7 = 35, leading to 3,500.\\n\\nFor the tens place: 30 + 50 + 40 + 80 + 10 + 80 = 290.\\n**Correction:** Your initial assumption about tens and ones places was wrong. You incorrectly stated they contribute nothing. The correct sum of tens digits is 3 + 5 + 4 + 8 + 1 + 8 = 29, leading to 290.\\n\\nFor the ones place: 0 + 3 + 7 + 5 + 9 + 0 = 24.\\n**Correction:**  The correct sum of ones digits is 0 + 3 + 7 + 5 + 9 + 0 = 24.\\n\\nNow, adding all these together: 23,000,000 + 2,500,000 + 290,000 + 24,000 + 3,500 + 290 + 24 = 25,817,814.\\n**Correction:** Your final summation using your initially calculated incorrect values was 14,000,000 + 900,000 + 21,000 + 2,000 + 140 = 14,923,140, which is incorrect. Using the correctly calculated place values, the sum is 25,817,814.\\n\\nThe final answer is $\\\\boxed{25817814}$</think><answer>25817814</answer>\"}]\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"dataset = formatted_entries","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:16:43.830355Z","iopub.execute_input":"2025-03-19T01:16:43.830686Z","iopub.status.idle":"2025-03-19T01:16:43.834567Z","shell.execute_reply.started":"2025-03-19T01:16:43.830664Z","shell.execute_reply":"2025-03-19T01:16:43.833640Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from unsloth.chat_templates import get_chat_template\n\ntokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"llama-3.1\",\n)\n\ndef formatting_prompts_func(examples):\n    convos = examples[\"conversations\"]\n    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n    return { \"text\" : texts, }\npass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:16:47.568119Z","iopub.execute_input":"2025-03-19T01:16:47.568476Z","iopub.status.idle":"2025-03-19T01:16:47.574105Z","shell.execute_reply.started":"2025-03-19T01:16:47.568449Z","shell.execute_reply":"2025-03-19T01:16:47.573299Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"from datasets import Dataset\n\nif isinstance(dataset, list):\n    dataset = Dataset.from_list(dataset) # convert to an instance of DataSet module","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:16:49.163926Z","iopub.execute_input":"2025-03-19T01:16:49.164216Z","iopub.status.idle":"2025-03-19T01:16:49.188795Z","shell.execute_reply.started":"2025-03-19T01:16:49.164194Z","shell.execute_reply":"2025-03-19T01:16:49.187814Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"from unsloth.chat_templates import standardize_sharegpt\ndataset = standardize_sharegpt(dataset)\ndataset = dataset.map(formatting_prompts_func, batched = True,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:16:52.373797Z","iopub.execute_input":"2025-03-19T01:16:52.374081Z","iopub.status.idle":"2025-03-19T01:16:53.332023Z","shell.execute_reply.started":"2025-03-19T01:16:52.374059Z","shell.execute_reply":"2025-03-19T01:16:53.331214Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Standardizing formats (num_proc=4):   0%|          | 0/1051 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72bc580d211a42c9910a6410c273b9b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1051 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1f574ce7d0a492b95a139d889b1ab60"}},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"dataset[5][\"conversations\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:16:56.736964Z","iopub.execute_input":"2025-03-19T01:16:56.737315Z","iopub.status.idle":"2025-03-19T01:16:56.743458Z","shell.execute_reply.started":"2025-03-19T01:16:56.737264Z","shell.execute_reply":"2025-03-19T01:16:56.742657Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"[{'content': \"Add 116407, 5815870, 7815927, 9573452, 3242956, 3495139 <think>To find the sum of all these numbers, I'll start by adding 116407 and 5815870. \\n\\nNext, I'll add 7815927 to the result from the previous step.\\n\\nThen, I'll add 9573452 to this new total.\\n\\nAfter that, I'll add 3242956 to continue building up the sum.\\n\\nFinally, I'll add 3495139 to reach the final sum of all numbers.\",\n  'role': 'user'},\n {'content': 'To find the sum of [116407, 5815870, 7815927, 9573452, 3242956, 3495139], we will follow the steps outlined:\\n\\nFirst, add 116407 and 5815870:\\n116407 + 5815870 = 5932277\\n\\nNext, add 7815927 to the result:\\n5932277 + 7815927 = 13748204\\n\\nThen, add 9573452 to the new total:\\n13748204 + 9573452 = 23321656\\n\\nAfter that, add 3242956:\\n23321656 + 3242956 = 26564612\\n\\nFinally, add 3495139 to reach the final sum:\\n26564612 + 3495139 = 30059751\\n\\nTherefore, the sum of [116407, 5815870, 7815927, 9573452, 3242956, 3495139] is 30059751.\\n\\nFinal Answer: The final answer is $\\\\boxed{30059751}$</think><answer>30059751</answer>',\n  'role': 'assistant'}]"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"dataset[5][\"text\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:17:07.254662Z","iopub.execute_input":"2025-03-19T01:17:07.254952Z","iopub.status.idle":"2025-03-19T01:17:07.260542Z","shell.execute_reply.started":"2025-03-19T01:17:07.254930Z","shell.execute_reply":"2025-03-19T01:17:07.259498Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"\"<ï½œbeginâ–ofâ–sentenceï½œ><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nAdd 116407, 5815870, 7815927, 9573452, 3242956, 3495139 <think>To find the sum of all these numbers, I'll start by adding 116407 and 5815870. \\n\\nNext, I'll add 7815927 to the result from the previous step.\\n\\nThen, I'll add 9573452 to this new total.\\n\\nAfter that, I'll add 3242956 to continue building up the sum.\\n\\nFinally, I'll add 3495139 to reach the final sum of all numbers.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nTo find the sum of [116407, 5815870, 7815927, 9573452, 3242956, 3495139], we will follow the steps outlined:\\n\\nFirst, add 116407 and 5815870:\\n116407 + 5815870 = 5932277\\n\\nNext, add 7815927 to the result:\\n5932277 + 7815927 = 13748204\\n\\nThen, add 9573452 to the new total:\\n13748204 + 9573452 = 23321656\\n\\nAfter that, add 3242956:\\n23321656 + 3242956 = 26564612\\n\\nFinally, add 3495139 to reach the final sum:\\n26564612 + 3495139 = 30059751\\n\\nTherefore, the sum of [116407, 5815870, 7815927, 9573452, 3242956, 3495139] is 30059751.\\n\\nFinal Answer: The final answer is $\\\\boxed{30059751}$</think><answer>30059751</answer><|eot_id|>\""},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments, DataCollatorForSeq2Seq\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        # num_train_epochs = 1, # Set this for 1 full training run.\n        max_steps = 60,\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"none\", # Use this for WandB etc\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:17:10.111310Z","iopub.execute_input":"2025-03-19T01:17:10.111644Z","iopub.status.idle":"2025-03-19T01:17:13.282763Z","shell.execute_reply.started":"2025-03-19T01:17:10.111619Z","shell.execute_reply":"2025-03-19T01:17:13.281795Z"}},"outputs":[{"name":"stdout","text":"Unsloth: We found double BOS tokens - we shall remove one automatically.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/1051 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3400175791f844069a4ec06a3cd3820a"}},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"from unsloth.chat_templates import train_on_responses_only\ntrainer = train_on_responses_only(\n    trainer,\n    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:17:29.171856Z","iopub.execute_input":"2025-03-19T01:17:29.172208Z","iopub.status.idle":"2025-03-19T01:17:30.356353Z","shell.execute_reply.started":"2025-03-19T01:17:29.172176Z","shell.execute_reply":"2025-03-19T01:17:30.355357Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1051 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ca4c46fb7de4fcd814d8493d9dac347"}},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:17:36.625819Z","iopub.execute_input":"2025-03-19T01:17:36.626148Z","iopub.status.idle":"2025-03-19T01:17:36.635840Z","shell.execute_reply.started":"2025-03-19T01:17:36.626120Z","shell.execute_reply":"2025-03-19T01:17:36.634996Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"\"<ï½œbeginâ–ofâ–sentenceï½œ><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nAdd 116407, 5815870, 7815927, 9573452, 3242956, 3495139 <think>To find the sum of all these numbers, I'll start by adding 116407 and 5815870. \\n\\nNext, I'll add 7815927 to the result from the previous step.\\n\\nThen, I'll add 9573452 to this new total.\\n\\nAfter that, I'll add 3242956 to continue building up the sum.\\n\\nFinally, I'll add 3495139 to reach the final sum of all numbers.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nTo find the sum of [116407, 5815870, 7815927, 9573452, 3242956, 3495139], we will follow the steps outlined:\\n\\nFirst, add 116407 and 5815870:\\n116407 + 5815870 = 5932277\\n\\nNext, add 7815927 to the result:\\n5932277 + 7815927 = 13748204\\n\\nThen, add 9573452 to the new total:\\n13748204 + 9573452 = 23321656\\n\\nAfter that, add 3242956:\\n23321656 + 3242956 = 26564612\\n\\nFinally, add 3495139 to reach the final sum:\\n26564612 + 3495139 = 30059751\\n\\nTherefore, the sum of [116407, 5815870, 7815927, 9573452, 3242956, 3495139] is 30059751.\\n\\nFinal Answer: The final answer is $\\\\boxed{30059751}$</think><answer>30059751</answer><|eot_id|>\""},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T18:11:12.123800Z","iopub.execute_input":"2025-03-10T18:11:12.124185Z","iopub.status.idle":"2025-03-10T18:11:12.131334Z","shell.execute_reply.started":"2025-03-10T18:11:12.124155Z","shell.execute_reply":"2025-03-10T18:11:12.130556Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\ntokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T18:11:21.569403Z","iopub.execute_input":"2025-03-10T18:11:21.569942Z","iopub.status.idle":"2025-03-10T18:11:21.585616Z","shell.execute_reply.started":"2025-03-10T18:11:21.569896Z","shell.execute_reply":"2025-03-10T18:11:21.584633Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"\"                                                                                                                                                                       \\n\\nTo find the total sum of these numbers, I'll start by aligning them vertically, ensuring that each digit is in the correct place value.\\n\\nNext, I'll add each column starting from the rightmost digit. If the sum of any column exceeds 9, I'll carry over the extra to the next higher place value.\\n\\nAfter completing the addition for all columns, I'll read the final result as the total sum.</think>\\n<answer>30,059,751</answer><|eot_id|>\""},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T01:17:55.542799Z","iopub.execute_input":"2025-03-19T01:17:55.543100Z","iopub.status.idle":"2025-03-19T02:05:30.611494Z","shell.execute_reply.started":"2025-03-19T01:17:55.543070Z","shell.execute_reply":"2025-03-19T02:05:30.610531Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 1,051 | Num Epochs = 1 | Total steps = 60\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 46:38, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.576800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.704400</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.645300</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.603800</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.576800</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.411100</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.338900</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.371600</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.350600</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.388400</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.351000</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.322100</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.388700</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.329600</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.262900</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.217000</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.255300</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.361500</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.335200</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.256200</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.362600</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.298800</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.238200</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.288300</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.344400</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.355500</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.195700</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.271900</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.233600</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.207900</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.242400</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.297600</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.187600</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.241300</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.195400</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.223000</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.195000</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.324000</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.334300</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.264000</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.206600</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.180300</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.244700</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.168600</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.300500</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.271300</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.228800</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.272600</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.196500</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.209700</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.190700</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.237800</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.235600</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.174500</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.159000</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.282600</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.206500</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.168900</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.241000</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.230200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"model.save_pretrained(\"finetuned_r1-8BNew\")\ntokenizer.save_pretrained(\"finetuned_r1-8BNew\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T02:06:03.488887Z","iopub.execute_input":"2025-03-19T02:06:03.489179Z","iopub.status.idle":"2025-03-19T02:06:04.093527Z","shell.execute_reply.started":"2025-03-19T02:06:03.489157Z","shell.execute_reply":"2025-03-19T02:06:04.092698Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"('finetuned_r1-8BNew/tokenizer_config.json',\n 'finetuned_r1-8BNew/special_tokens_map.json',\n 'finetuned_r1-8BNew/tokenizer.json')"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"if False:\n    from unsloth import FastLanguageModel\n    model, tokenizer = FastLanguageModel.from_pretrained(\n        model_name = \"finetuned_r1-8BNew\", # YOUR MODEL YOU USED FOR TRAINING\n        max_seq_length = max_seq_length,\n        dtype = dtype,\n        load_in_4bit = load_in_4bit,\n    )\n    FastLanguageModel.for_inference(model) # Enable native 2x faster inference","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T02:06:27.940210Z","iopub.execute_input":"2025-03-19T02:06:27.940530Z","iopub.status.idle":"2025-03-19T02:06:27.944834Z","shell.execute_reply.started":"2025-03-19T02:06:27.940508Z","shell.execute_reply":"2025-03-19T02:06:27.943877Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"messages = [\n    {\"role\": \"user\", \"content\": \"Add 55589+6664317\"},\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T02:12:20.997083Z","iopub.execute_input":"2025-03-19T02:12:20.997468Z","iopub.status.idle":"2025-03-19T02:12:21.001226Z","shell.execute_reply.started":"2025-03-19T02:12:20.997434Z","shell.execute_reply":"2025-03-19T02:12:21.000313Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"inputs = tokenizer.apply_chat_template(\n    messages,\n    tokenize = True,\n    add_generation_prompt = True, # Must add for generation\n    return_tensors = \"pt\",\n).to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T02:12:21.476306Z","iopub.execute_input":"2025-03-19T02:12:21.476621Z","iopub.status.idle":"2025-03-19T02:12:21.480945Z","shell.execute_reply.started":"2025-03-19T02:12:21.476597Z","shell.execute_reply":"2025-03-19T02:12:21.480260Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"from transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer, skip_prompt = True)\n_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens =1024,\n                   use_cache = True, temperature = 0.1, min_p = 0.1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(55589+6664317)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T02:07:52.488466Z","iopub.execute_input":"2025-03-19T02:07:52.488780Z","iopub.status.idle":"2025-03-19T02:07:52.493165Z","shell.execute_reply.started":"2025-03-19T02:07:52.488758Z","shell.execute_reply":"2025-03-19T02:07:52.492366Z"}},"outputs":[{"name":"stdout","text":"6719906\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}